{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43046c4f-bf72-4ec9-bf20-c4b3ba57bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALISH\\anaconda3\\Lib\\site-packages\\langchain_ollama\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_ollama.chat_models import ChatOllama\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Ollama model 'gemma:2b' initialized for LLM and Embedder.\n",
      "PDF extraction function defined.\n",
      "Invoice data processing function defined.\n",
      "RAG prompt template defined (for natural language output).\n",
      "RAG prompt template defined.\n",
      "Using invoice at: C:\\Users\\ALISH\\Agent Practice\\tmp\\invoice.pdf\n",
      "Processing PDF: C:\\Users\\ALISH\\Agent Practice\\tmp\\invoice.pdf\n",
      "Split PDF into 2 chunks.\n",
      "Using embedding dimension: 2048\n",
      "Created new table with proper schema\n",
      "Successfully inserted 2 chunks\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup (UPDATED)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# LangChain components for LLM and RAG\n",
    "# from langchain_community.llms import Ollama as LCOllama <-- OLD\n",
    "# from langchain_ollama import Ollama as LCOllama <-- Incorrect Name\n",
    "from langchain_ollama import OllamaLLM as LCOllama # <-- NEW: Corrected Class Name import\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document as LangChainDocument\n",
    "import uuid  \n",
    "import pyarrow as pa \n",
    "# phi-agent components\n",
    "from phi.model.ollama import Ollama as PhiOllama\n",
    "from phi.vectordb.lancedb import LanceDb, SearchType\n",
    "from phi.embedder.ollama import OllamaEmbedder as PhiOllamaEmbedder\n",
    "from phi.document import Document as PhiDocument\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk, scrolledtext\n",
    "from tkinter import font as tkfont\n",
    "# PDF processing\n",
    "import PyPDF2\n",
    "\n",
    "# For creating a dummy PDF (optional)\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas as r_canvas\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n",
    "# Cell 2: Ollama Model Initialization (No Changes)\n",
    "\n",
    "model_id = \"gemma:2b\"\n",
    "# Initialize Ollama model for phi-agent\n",
    "phi_ollama_model = PhiOllama(id=model_id)\n",
    "# Initialize Ollama embedder for phi-agent's vector DB\n",
    "phi_ollama_embedder = PhiOllamaEmbedder(model=model_id)\n",
    "\n",
    "print(f\"Ollama model '{model_id}' initialized for LLM and Embedder.\")\n",
    "\n",
    "\n",
    "# Cell 3: PDF Text Extraction Function (No Changes)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from a given PDF file using PyPDF2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"PDF extraction function defined.\")\n",
    "\n",
    "\n",
    "def process_invoice_data(pdf_path: str) -> list[PhiDocument]:\n",
    "    \"\"\"\n",
    "    Extracts text from PDF and returns properly formatted PhiDocuments\n",
    "    \"\"\"\n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        print(\"No text extracted from PDF.\")\n",
    "        return []\n",
    "\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    \n",
    "    # Split text and create PhiDocuments\n",
    "    text_chunks = text_splitter.split_text(text)\n",
    "    phi_chunks = [\n",
    "        PhiDocument(\n",
    "            name=f\"chunk_{i}\",\n",
    "            content=chunk,  # Using 'content' consistently\n",
    "            meta={\"source\": pdf_path}\n",
    "        )\n",
    "        for i, chunk in enumerate(text_chunks)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Split PDF into {len(phi_chunks)} chunks.\")\n",
    "    return phi_chunks\n",
    "print(\"Invoice data processing function defined.\")\n",
    "\n",
    "\n",
    "# Cell 5: Setup Vector Database (LanceDB) (No Changes)\n",
    "\n",
    "def setup_vector_db(chunks: list[PhiDocument]) -> LanceDb:\n",
    "    \"\"\"\n",
    "    Fixed setup with proper schema alignment\n",
    "    \"\"\"\n",
    "    import lancedb\n",
    "    \n",
    "    db_uri = \"tmp/lancedb_invoices\"\n",
    "    os.makedirs(db_uri, exist_ok=True)\n",
    "    \n",
    "    # Connect to LanceDB\n",
    "    db = lancedb.connect(db_uri)\n",
    "    \n",
    "    # Get embedding dimension\n",
    "    try:\n",
    "        test_embedding = phi_ollama_embedder.get_embedding(\"test\")\n",
    "        dim = len(test_embedding)\n",
    "        print(f\"Using embedding dimension: {dim}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding dimension: {e}\")\n",
    "        dim = 2048  # Default for gemma:2b\n",
    "        print(f\"Using default dimension: {dim}\")\n",
    "\n",
    "    # Define schema that matches our data structure\n",
    "    schema = pa.schema([\n",
    "        pa.field(\"id\", pa.string()),\n",
    "        pa.field(\"content\", pa.string()),  # Changed from 'text' to 'content'\n",
    "        pa.field(\"vector\", pa.list_(pa.float32(), dim)),\n",
    "        pa.field(\"metadata\", pa.string())\n",
    "    ])\n",
    "    \n",
    "    # Table handling - always create new table to avoid schema conflicts\n",
    "    if os.path.exists(db_uri):\n",
    "        import shutil\n",
    "        shutil.rmtree(db_uri)\n",
    "        os.makedirs(db_uri, exist_ok=True)\n",
    "    \n",
    "    table = db.create_table(\"invoice_data\", schema=schema)\n",
    "    print(\"Created new table with proper schema\")\n",
    "    \n",
    "    # Document insertion\n",
    "    if chunks:\n",
    "        data = []\n",
    "        for chunk in chunks:\n",
    "            try:\n",
    "                embedding = phi_ollama_embedder.get_embedding(chunk.content)\n",
    "                data.append({\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"content\": chunk.content,  # Changed from 'text' to 'content'\n",
    "                    \"vector\": embedding,\n",
    "                    \"metadata\": json.dumps(chunk.meta if hasattr(chunk, 'meta') else {})\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if data:\n",
    "            table.add(data)\n",
    "            print(f\"Successfully inserted {len(data)} chunks\")\n",
    "        else:\n",
    "            print(\"No valid chunks to insert\")\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "# Cell 6: Define RAG Prompt (No Changes)\n",
    "\n",
    "# Cell 6: Define RAG Prompt (MODIFIED)\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are an expert AI assistant specialized in extracting precise details from invoice documents. \"\n",
    "        \"Your goal is to accurately answer questions based *only* on the provided invoice context. \"\n",
    "        \"If the information is not present in the context, state that you cannot find it.\"\n",
    "        \"\\n---CONTEXT---\\n\"\n",
    "        \"{context}\"\n",
    "    )),\n",
    "    (\"human\", \"Query: {query}\")\n",
    "])\n",
    "\n",
    "print(\"RAG prompt template defined (for natural language output).\")\n",
    "\n",
    "print(\"RAG prompt template defined.\")\n",
    "\n",
    "# Cell 7: Main Execution Flow (UPDATED)\n",
    "# Cell 7: Main Execution Flow (Updated)\n",
    "def main():\n",
    "    # Setup: Create 'tmp' folder and define invoice PDF path\n",
    "    pdf_dir = os.path.join(os.getcwd(), \"tmp\")\n",
    "    os.makedirs(pdf_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(pdf_dir, \"invoice.pdf\")\n",
    "\n",
    "    # Check if invoice exists - exit if not found\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"Invoice PDF not found at: {pdf_path}\")\n",
    "        print(\"Please provide an invoice PDF file named 'invoice.pdf' in the tmp directory\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Using invoice at: {pdf_path}\")\n",
    "\n",
    "    # Process PDF and setup the vector database\n",
    "    chunks = process_invoice_data(pdf_path)\n",
    "    if not chunks:\n",
    "        print(\"Exiting: No text found in PDF.\")\n",
    "        return None\n",
    "    \n",
    "    vector_db_instance = setup_vector_db(chunks)\n",
    "    return vector_db_instance\n",
    "    \n",
    "def query_invoice_data(vector_db: LanceDb, question: str, text_widget: scrolledtext.ScrolledText):\n",
    "    \"\"\"\n",
    "    Query the invoice data and display results in the Tkinter widget\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the question\n",
    "        query_embedding = phi_ollama_embedder.get_embedding(question)\n",
    "        \n",
    "        # Perform the search\n",
    "        results = vector_db.search(query_embedding).limit(3).to_list()\n",
    "        context = \"\\n\".join([result[\"content\"] for result in results])\n",
    "        \n",
    "        # Setup LLM chain\n",
    "        llm = LCOllama(model=model_id)\n",
    "        chain = rag_prompt_template | llm | StrOutputParser()\n",
    "        \n",
    "        # Get answer\n",
    "        response = chain.invoke({\"context\": context, \"query\": question})\n",
    "        \n",
    "        # Format the output for GUI\n",
    "        text_widget.configure(state='normal')\n",
    "        text_widget.insert(tk.END, f\"Question: {question}\\n\", 'question')\n",
    "        \n",
    "        # Clean up and format the response\n",
    "        if response.startswith(\"{\") and response.endswith(\"}\"):\n",
    "            try:\n",
    "                data = json.loads(response)\n",
    "                formatted_response = \"\\n\".join([f\"  • {k.replace('_', ' ').title()}: {v}\" \n",
    "                                              for k, v in data.items()])\n",
    "                text_widget.insert(tk.END, f\"Answer:\\n{formatted_response}\\n\\n\", 'answer')\n",
    "            except json.JSONDecodeError:\n",
    "                text_widget.insert(tk.END, f\"Answer: {response}\\n\\n\", 'answer')\n",
    "        else:\n",
    "            text_widget.insert(tk.END, f\"Answer: {response}\\n\\n\", 'answer')\n",
    "        \n",
    "        text_widget.configure(state='disabled')\n",
    "        text_widget.see(tk.END)\n",
    "        \n",
    "    except Exception as e:\n",
    "        text_widget.configure(state='normal')\n",
    "        text_widget.insert(tk.END, f\"Error processing question: {e}\\n\\n\", 'error')\n",
    "        text_widget.configure(state='disabled')\n",
    "\n",
    "# Replace the if __name__ == \"__main__\": block with this:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Invoice Query System\")\n",
    "    root.geometry(\"800x600\")\n",
    "    \n",
    "    # Configure styles\n",
    "    style = ttk.Style()\n",
    "    style.configure('TFrame', background='#f0f0f0')\n",
    "    style.configure('TLabel', background='#f0f0f0', font=('Arial', 10, 'bold'))\n",
    "    \n",
    "    # Create fonts\n",
    "    title_font = tkfont.Font(family='Helvetica', size=12, weight='bold')\n",
    "    question_font = tkfont.Font(family='Helvetica', size=10, weight='bold')\n",
    "    answer_font = tkfont.Font(family='Helvetica', size=10)\n",
    "    \n",
    "    # Main container\n",
    "    main_frame = ttk.Frame(root)\n",
    "    main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "    \n",
    "    # Header\n",
    "    header_frame = ttk.Frame(main_frame)\n",
    "    header_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "    \n",
    "    ttk.Label(header_frame, text=\"Invoice Query System\", font=title_font).pack(side=tk.TOP)\n",
    "    \n",
    "    # Output area\n",
    "    output_frame = ttk.Frame(main_frame)\n",
    "    output_frame.pack(fill=tk.BOTH, expand=True)\n",
    "    \n",
    "    output_text = scrolledtext.ScrolledText(\n",
    "        output_frame,\n",
    "        wrap=tk.WORD,\n",
    "        width=80,\n",
    "        height=25,\n",
    "        font=answer_font\n",
    "    )\n",
    "    output_text.pack(fill=tk.BOTH, expand=True)\n",
    "    \n",
    "    # Configure tags for text styling\n",
    "    output_text.tag_configure('question', foreground='blue', font=question_font)\n",
    "    output_text.tag_configure('answer', foreground='green')\n",
    "    output_text.tag_configure('error', foreground='red')\n",
    "    \n",
    "    # Get the vector db instance\n",
    "    vector_db = main()\n",
    "    \n",
    "    if vector_db:\n",
    "        output_text.insert(tk.END, \"Invoice Query System Ready!\\n\\n\", 'title')\n",
    "        \n",
    "        # List of questions to ask\n",
    "        questions = [\n",
    "            \"What is the total amount due for this invoice?\",\n",
    "            \"Who is the customer and what is their address?\",\n",
    "            \"What is the Invoice Number and Date?\",\n",
    "            \"What are the payment terms?\",\n",
    "            \"Who is the salesperson mentioned on the invoice?\",\n",
    "            \"What is the description of the item purchased and its quantity?\",\n",
    "            \"What is the unit price of the decorative clay pottery?\",\n",
    "            \"What is the subtotal before taxes and shipping?\",\n",
    "            \"How much is the sales tax and shipping & handling?\",\n",
    "            \"Are there any special instructions or comments about the shipment?\"\n",
    "        ]\n",
    "        \n",
    "        # Process each question\n",
    "        for question in questions:\n",
    "            query_invoice_data(vector_db, question, output_text)\n",
    "            \n",
    "        # Add status message\n",
    "        output_text.configure(state='normal')\n",
    "        output_text.insert(tk.END, \"\\nAll queries completed.\\n\", 'title')\n",
    "        output_text.configure(state='disabled')\n",
    "    else:\n",
    "        output_text.insert(tk.END, \"Failed to initialize vector database\\n\", 'error')\n",
    "    \n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0615a-7490-4bb6-97d9-451db224c9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d56cd-a087-4796-8a98-3b8bacc1901c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b451df-2466-42ca-9fde-265005460087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Ollama model 'gemma:2b' initialized for LLM and Embedder.\n",
      "PDF extraction function defined.\n",
      "Invoice data processing function defined.\n",
      "RAG prompt template defined.\n",
      "Using existing invoice.pdf at: C:\\Users\\ALISH\\Agent Practice\\tmp\\invoice.pdf\n",
      "Processing PDF: C:\\Users\\ALISH\\Agent Practice\\tmp\\invoice.pdf\n",
      "Split PDF into 2 chunks.\n",
      "Using embedding dimension: 2048\n",
      "Created new table with proper schema\n",
      "Successfully inserted 2 chunks\n",
      "\n",
      "Invoice Query System Ready!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the total amount due for this invoice?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"total_due\": 1389.99\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Who is the customer and what is their address?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"customer_name\": \"Mollie Grau\",\n",
       "  \"customer_address\": \"210 Stars Avenue, Berkeley, CA 78910\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the Invoice Number and Date?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"invoice_number\": \"100\",\n",
       "  \"invoice_date\": \"1/1/23\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What are the payment terms?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"payment_terms\": \"Due on receipt\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Who is the salesperson mentioned on the invoice?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** The context does not provide any information about the salesperson, so I cannot extract the requested data from the context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the description of the item purchased and its quantity?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"description\": \"Decorative clay pottery (LG)\",\n",
       "  \"quantity\": 100\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the unit price of the decorative clay pottery?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"unit_price\": 13.00\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the subtotal before taxes and shipping?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"subtotal\": 1300.00,\n",
       "  \"sales_tax\": 65.00,\n",
       "  \"shipping_handling\": 24.99,\n",
       "  \"total_due\": 1389.99\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** How much is the sales tax and shipping & handling?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"sales_tax\": 65,\n",
       "  \"shipping_handling\": 24.99\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Are there any special instructions or comments about the shipment?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"special_instructions\": \"Shipment contains fragile goods\",\n",
       "  \"comments\": \"Shipment contains fragile goods\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the phone number of Pottery & Co.?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"phone_number\": \"(123) 456 -7890\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup (UPDATED)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# LangChain components for LLM and RAG\n",
    "# from langchain_community.llms import Ollama as LCOllama <-- OLD\n",
    "# from langchain_ollama import Ollama as LCOllama <-- Incorrect Name\n",
    "from langchain_ollama import OllamaLLM as LCOllama # <-- NEW: Corrected Class Name import\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document as LangChainDocument\n",
    "import uuid  \n",
    "import pyarrow as pa \n",
    "# phi-agent components\n",
    "from phi.model.ollama import Ollama as PhiOllama\n",
    "from phi.vectordb.lancedb import LanceDb, SearchType\n",
    "from phi.embedder.ollama import OllamaEmbedder as PhiOllamaEmbedder\n",
    "from phi.document import Document as PhiDocument\n",
    "\n",
    "# PDF processing\n",
    "import PyPDF2\n",
    "\n",
    "# For creating a dummy PDF (optional)\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas as r_canvas\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n",
    "# Cell 2: Ollama Model Initialization (No Changes)\n",
    "\n",
    "model_id = \"gemma:2b\"\n",
    "# Initialize Ollama model for phi-agent\n",
    "phi_ollama_model = PhiOllama(id=model_id)\n",
    "# Initialize Ollama embedder for phi-agent's vector DB\n",
    "phi_ollama_embedder = PhiOllamaEmbedder(model=model_id)\n",
    "\n",
    "print(f\"Ollama model '{model_id}' initialized for LLM and Embedder.\")\n",
    "\n",
    "\n",
    "# Cell 3: PDF Text Extraction Function (No Changes)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from a given PDF file using PyPDF2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"PDF extraction function defined.\")\n",
    "\n",
    "\n",
    "def process_invoice_data(pdf_path: str) -> list[PhiDocument]:\n",
    "    \"\"\"\n",
    "    Extracts text from PDF and returns properly formatted PhiDocuments\n",
    "    \"\"\"\n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        print(\"No text extracted from PDF.\")\n",
    "        return []\n",
    "\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    \n",
    "    # Split text and create PhiDocuments\n",
    "    text_chunks = text_splitter.split_text(text)\n",
    "    phi_chunks = [\n",
    "        PhiDocument(\n",
    "            name=f\"chunk_{i}\",\n",
    "            content=chunk,  # Using 'content' consistently\n",
    "            meta={\"source\": pdf_path}\n",
    "        )\n",
    "        for i, chunk in enumerate(text_chunks)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Split PDF into {len(phi_chunks)} chunks.\")\n",
    "    return phi_chunks\n",
    "print(\"Invoice data processing function defined.\")\n",
    "\n",
    "\n",
    "# Cell 5: Setup Vector Database (LanceDB) (No Changes)\n",
    "\n",
    "def setup_vector_db(chunks: list[PhiDocument]) -> LanceDb:\n",
    "    \"\"\"\n",
    "    More robust database setup with proper cleanup\n",
    "    \"\"\"\n",
    "    import lancedb\n",
    "    \n",
    "    db_uri = \"tmp/lancedb_invoices\"\n",
    "    \n",
    "    # Clean up any existing database\n",
    "    if os.path.exists(db_uri):\n",
    "        try:\n",
    "            import shutil\n",
    "            shutil.rmtree(db_uri)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not clean database directory: {e}\")\n",
    "    \n",
    "    os.makedirs(db_uri, exist_ok=True)\n",
    "    \n",
    "    # Connect to LanceDB with retry logic\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            db = lancedb.connect(db_uri)\n",
    "            \n",
    "            # Get embedding dimension\n",
    "            test_embedding = phi_ollama_embedder.get_embedding(\"test\")\n",
    "            dim = len(test_embedding)\n",
    "            print(f\"Using embedding dimension: {dim}\")\n",
    "            \n",
    "            # Define schema\n",
    "            schema = pa.schema([\n",
    "                pa.field(\"id\", pa.string()),\n",
    "                pa.field(\"content\", pa.string()),\n",
    "                pa.field(\"vector\", pa.list_(pa.float32(), dim)),\n",
    "                pa.field(\"metadata\", pa.string())\n",
    "            ])\n",
    "            \n",
    "            # Create table\n",
    "            table = db.create_table(\"invoice_data\", schema=schema)\n",
    "            print(\"Created new table with proper schema\")\n",
    "            \n",
    "            # Insert documents with batch processing\n",
    "            if chunks:\n",
    "                data = []\n",
    "                for chunk in chunks:\n",
    "                    try:\n",
    "                        embedding = phi_ollama_embedder.get_embedding(chunk.content)\n",
    "                        data.append({\n",
    "                            \"id\": str(uuid.uuid4()),\n",
    "                            \"content\": chunk.content,\n",
    "                            \"vector\": embedding,\n",
    "                            \"metadata\": json.dumps(chunk.meta if hasattr(chunk, 'meta') else {})\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing chunk: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if data:\n",
    "                    # Insert in batches to prevent timeouts\n",
    "                    batch_size = 5\n",
    "                    for i in range(0, len(data), batch_size):\n",
    "                        batch = data[i:i + batch_size]\n",
    "                        table.add(batch)\n",
    "                    print(f\"Successfully inserted {len(data)} chunks\")\n",
    "                else:\n",
    "                    print(\"No valid chunks to insert\")\n",
    "            \n",
    "            return table\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying... Error: {e}\")\n",
    "            time.sleep(1)  # Add delay between retries\n",
    "# Cell 6: Define RAG Prompt (No Changes)\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are an expert AI assistant specialized in extracting precise details from invoice documents. \"\n",
    "        \"Your goal is to accurately answer questions based *only* on the provided invoice context. \"\n",
    "        \"If the information is not present in the context, state that you cannot find it. \"\n",
    "        \"For all extractions, return the response in a clear JSON format with appropriate keys for the extracted data.\"\n",
    "        \"\\n---CONTEXT---\\n\"\n",
    "        \"{context}\"\n",
    "    )),\n",
    "    (\"human\", \"Query: {query}\")\n",
    "])\n",
    "\n",
    "print(\"RAG prompt template defined.\")\n",
    "\n",
    "# Cell 7: Main Execution Flow (UPDATED)\n",
    "# Cell 7: Main Execution Flow (Updated)\n",
    "def main():\n",
    "    # Setup: Create 'tmp' folder and define invoice PDF path\n",
    "    pdf_dir = os.path.join(os.getcwd(), \"tmp\")\n",
    "    os.makedirs(pdf_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(pdf_dir, \"invoice.pdf\")\n",
    "\n",
    "    # Create a dummy invoice if it doesn't exist\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(\"Creating a dummy 'invoice.pdf' for demonstration.\")\n",
    "        c = r_canvas.Canvas(pdf_path, pagesize=letter)\n",
    "        c.drawString(100, 750, \"Invoice No: INV-2023-001\")\n",
    "        c.drawString(100, 730, \"Invoice Date: October 26, 2023\")\n",
    "        c.drawString(100, 710, \"Customer: ABC Corp\")\n",
    "        c.drawString(100, 690, \"Total Amount Due: $1234.56 USD\")\n",
    "        c.drawString(100, 670, \"Payment Terms: Net 30\")\n",
    "        c.drawString(100, 650, \"Line Item 1: Product X - Quantity: 2 - Price: $300.00 - Total: $600.00\")\n",
    "        c.drawString(100, 630, \"Line Item 2: Service Y - Quantity: 1 - Price: $634.56 - Total: $634.56\")\n",
    "        c.save()\n",
    "    else:\n",
    "        print(f\"Using existing invoice.pdf at: {pdf_path}\")\n",
    "\n",
    "    # Process PDF and setup the vector database\n",
    "    chunks = process_invoice_data(pdf_path)\n",
    "    if not chunks:\n",
    "        print(\"Exiting: No text found in PDF.\")\n",
    "        return None\n",
    "    \n",
    "    vector_db_instance = setup_vector_db(chunks)\n",
    "    return vector_db_instance\n",
    "\n",
    "def query_invoice_data(vector_db: LanceDb, question: str):\n",
    "    \"\"\"\n",
    "    Query the invoice data using the vector database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the question\n",
    "        query_embedding = phi_ollama_embedder.get_embedding(question)\n",
    "        \n",
    "        # Perform the search (correct LanceDB syntax)\n",
    "        results = vector_db.search(query_embedding).limit(3).to_list()\n",
    "        \n",
    "        # Combine the context from top results\n",
    "        context = \"\\n\".join([result[\"content\"] for result in results])\n",
    "        \n",
    "        # Setup LLM chain\n",
    "        llm = LCOllama(model=model_id)\n",
    "        chain = rag_prompt_template | llm | StrOutputParser()\n",
    "        \n",
    "        # Get answer\n",
    "        response = chain.invoke({\n",
    "            \"context\": context,\n",
    "            \"query\": question\n",
    "        })\n",
    "        \n",
    "        display(Markdown(f\"**Question:** {question}\"))\n",
    "        display(Markdown(f\"**Answer:** {response}\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying data: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the vector db instance\n",
    "    vector_db = main()\n",
    "    \n",
    "    # Only run queries if we have a valid vector db\n",
    "    if vector_db:\n",
    "        print(\"\\nInvoice Query System Ready!\")\n",
    "        query_invoice_data(vector_db, \"What is the total amount due for this invoice?\")\n",
    "        query_invoice_data(vector_db, \"Who is the customer and what is their address?\")\n",
    "        query_invoice_data(vector_db, \"What is the Invoice Number and Date?\")\n",
    "        query_invoice_data(vector_db, \"What are the payment terms?\")\n",
    "        query_invoice_data(vector_db, \"Who is the salesperson mentioned on the invoice?\",)\n",
    "        query_invoice_data(vector_db, \"What is the description of the item purchased and its quantity?\")\n",
    "        query_invoice_data(vector_db,\"What is the unit price of the decorative clay pottery?\")\n",
    "        query_invoice_data(vector_db, \"What is the subtotal before taxes and shipping?\")\n",
    "        query_invoice_data(vector_db,\"How much is the sales tax and shipping & handling?\")\n",
    "        query_invoice_data(vector_db, \"Are there any special instructions or comments about the shipment?\")\n",
    "        query_invoice_data(vector_db,  \"What is the phone number of Pottery & Co.?\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Failed to initialize vector database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8ecaa-58f7-4e0f-bad5-557768df3e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
