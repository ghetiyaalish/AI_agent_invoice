{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73311631-5212-4ad0-be3c-f663364e35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --default-timeout=100 install -q ollama langchain langchain-community langchain-core pypdf reportlab lancedb beautifulsoup4 unstructured phidata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63ac8f-e481-4107-aba7-abd36620dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Ollama model 'gemma:2b' initialized for LLM and Embedder.\n",
      "PDF extraction function defined.\n",
      "Invoice data processing function defined.\n",
      "RAG prompt template defined.\n",
      "Using existing invoice.pdf at: C:\\Users\\ALISH\\Agent Practice\\tmp\\invoice.pdf\n",
      "Processing PDF: C:\\Users\\ALISH\\Agent Practice\\tmp\\invoice.pdf\n",
      "Split PDF into 2 chunks.\n",
      "Using embedding dimension: 2048\n",
      "Created new table with proper schema\n",
      "Successfully inserted 2 chunks\n",
      "\n",
      "Invoice Query System Ready!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the total amount due for this invoice?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"total_due\": 1389.99\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Who is the customer and what is their address?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"customer_name\": \"Mollie Grau\",\n",
       "  \"customer_address\": \"210 Stars Avenue, Berkeley, CA 78910\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the Invoice Number and Date?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"invoice_number\": \"100\",\n",
       "  \"date\": \"1/1/23\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup (UPDATED)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# LangChain components for LLM and RAG\n",
    "# from langchain_community.llms import Ollama as LCOllama <-- OLD\n",
    "# from langchain_ollama import Ollama as LCOllama <-- Incorrect Name\n",
    "from langchain_ollama import OllamaLLM as LCOllama # <-- NEW: Corrected Class Name import\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document as LangChainDocument\n",
    "import uuid  \n",
    "import pyarrow as pa \n",
    "# phi-agent components\n",
    "from phi.model.ollama import Ollama as PhiOllama\n",
    "from phi.vectordb.lancedb import LanceDb, SearchType\n",
    "from phi.embedder.ollama import OllamaEmbedder as PhiOllamaEmbedder\n",
    "from phi.document import Document as PhiDocument\n",
    "\n",
    "# PDF processing\n",
    "import PyPDF2\n",
    "\n",
    "# For creating a dummy PDF (optional)\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas as r_canvas\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n",
    "# Cell 2: Ollama Model Initialization (No Changes)\n",
    "\n",
    "model_id = \"gemma:2b\"\n",
    "# Initialize Ollama model for phi-agent\n",
    "phi_ollama_model = PhiOllama(id=model_id)\n",
    "# Initialize Ollama embedder for phi-agent's vector DB\n",
    "phi_ollama_embedder = PhiOllamaEmbedder(model=model_id)\n",
    "\n",
    "print(f\"Ollama model '{model_id}' initialized for LLM and Embedder.\")\n",
    "\n",
    "\n",
    "# Cell 3: PDF Text Extraction Function (No Changes)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from a given PDF file using PyPDF2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"PDF extraction function defined.\")\n",
    "\n",
    "\n",
    "def process_invoice_data(pdf_path: str) -> list[PhiDocument]:\n",
    "    \"\"\"\n",
    "    Extracts text from PDF and returns properly formatted PhiDocuments\n",
    "    \"\"\"\n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        print(\"No text extracted from PDF.\")\n",
    "        return []\n",
    "\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    \n",
    "    # Split text and create PhiDocuments\n",
    "    text_chunks = text_splitter.split_text(text)\n",
    "    phi_chunks = [\n",
    "        PhiDocument(\n",
    "            name=f\"chunk_{i}\",\n",
    "            content=chunk,  # Using 'content' consistently\n",
    "            meta={\"source\": pdf_path}\n",
    "        )\n",
    "        for i, chunk in enumerate(text_chunks)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Split PDF into {len(phi_chunks)} chunks.\")\n",
    "    return phi_chunks\n",
    "print(\"Invoice data processing function defined.\")\n",
    "\n",
    "\n",
    "# Cell 5: Setup Vector Database (LanceDB) (No Changes)\n",
    "\n",
    "def setup_vector_db(chunks: list[PhiDocument]) -> LanceDb:\n",
    "    \"\"\"\n",
    "    More robust database setup with proper cleanup\n",
    "    \"\"\"\n",
    "    import lancedb\n",
    "    \n",
    "    db_uri = \"tmp/lancedb_invoices\"\n",
    "    \n",
    "    # Clean up any existing database\n",
    "    if os.path.exists(db_uri):\n",
    "        try:\n",
    "            import shutil\n",
    "            shutil.rmtree(db_uri)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not clean database directory: {e}\")\n",
    "    \n",
    "    os.makedirs(db_uri, exist_ok=True)\n",
    "    \n",
    "    # Connect to LanceDB with retry logic\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            db = lancedb.connect(db_uri)\n",
    "            \n",
    "            # Get embedding dimension\n",
    "            test_embedding = phi_ollama_embedder.get_embedding(\"test\")\n",
    "            dim = len(test_embedding)\n",
    "            print(f\"Using embedding dimension: {dim}\")\n",
    "            \n",
    "            # Define schema\n",
    "            schema = pa.schema([\n",
    "                pa.field(\"id\", pa.string()),\n",
    "                pa.field(\"content\", pa.string()),\n",
    "                pa.field(\"vector\", pa.list_(pa.float32(), dim)),\n",
    "                pa.field(\"metadata\", pa.string())\n",
    "            ])\n",
    "            \n",
    "            # Create table\n",
    "            table = db.create_table(\"invoice_data\", schema=schema)\n",
    "            print(\"Created new table with proper schema\")\n",
    "            \n",
    "            # Insert documents with batch processing\n",
    "            if chunks:\n",
    "                data = []\n",
    "                for chunk in chunks:\n",
    "                    try:\n",
    "                        embedding = phi_ollama_embedder.get_embedding(chunk.content)\n",
    "                        data.append({\n",
    "                            \"id\": str(uuid.uuid4()),\n",
    "                            \"content\": chunk.content,\n",
    "                            \"vector\": embedding,\n",
    "                            \"metadata\": json.dumps(chunk.meta if hasattr(chunk, 'meta') else {})\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing chunk: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if data:\n",
    "                    # Insert in batches to prevent timeouts\n",
    "                    batch_size = 5\n",
    "                    for i in range(0, len(data), batch_size):\n",
    "                        batch = data[i:i + batch_size]\n",
    "                        table.add(batch)\n",
    "                    print(f\"Successfully inserted {len(data)} chunks\")\n",
    "                else:\n",
    "                    print(\"No valid chunks to insert\")\n",
    "            \n",
    "            return table\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying... Error: {e}\")\n",
    "            time.sleep(1)  # Add delay between retries\n",
    "# Cell 6: Define RAG Prompt (No Changes)\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are an expert AI assistant specialized in extracting precise details from invoice documents. \"\n",
    "        \"Your goal is to accurately answer questions based *only* on the provided invoice context. \"\n",
    "        \"If the information is not present in the context, state that you cannot find it. \"\n",
    "        \"For all extractions, return the response in a clear JSON format with appropriate keys for the extracted data.\"\n",
    "        \"\\n---CONTEXT---\\n\"\n",
    "        \"{context}\"\n",
    "    )),\n",
    "    (\"human\", \"Query: {query}\")\n",
    "])\n",
    "\n",
    "print(\"RAG prompt template defined.\")\n",
    "\n",
    "# Cell 7: Main Execution Flow (UPDATED)\n",
    "# Cell 7: Main Execution Flow (Updated)\n",
    "def main():\n",
    "    # Setup: Create 'tmp' folder and define invoice PDF path\n",
    "    pdf_dir = os.path.join(os.getcwd(), \"tmp\")\n",
    "    os.makedirs(pdf_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(pdf_dir, \"invoice.pdf\")\n",
    "\n",
    "    # Create a dummy invoice if it doesn't exist\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(\"Creating a dummy 'invoice.pdf' for demonstration.\")\n",
    "        c = r_canvas.Canvas(pdf_path, pagesize=letter)\n",
    "        c.drawString(100, 750, \"Invoice No: INV-2023-001\")\n",
    "        c.drawString(100, 730, \"Invoice Date: October 26, 2023\")\n",
    "        c.drawString(100, 710, \"Customer: ABC Corp\")\n",
    "        c.drawString(100, 690, \"Total Amount Due: $1234.56 USD\")\n",
    "        c.drawString(100, 670, \"Payment Terms: Net 30\")\n",
    "        c.drawString(100, 650, \"Line Item 1: Product X - Quantity: 2 - Price: $300.00 - Total: $600.00\")\n",
    "        c.drawString(100, 630, \"Line Item 2: Service Y - Quantity: 1 - Price: $634.56 - Total: $634.56\")\n",
    "        c.save()\n",
    "    else:\n",
    "        print(f\"Using existing invoice.pdf at: {pdf_path}\")\n",
    "\n",
    "    # Process PDF and setup the vector database\n",
    "    chunks = process_invoice_data(pdf_path)\n",
    "    if not chunks:\n",
    "        print(\"Exiting: No text found in PDF.\")\n",
    "        return None\n",
    "    \n",
    "    vector_db_instance = setup_vector_db(chunks)\n",
    "    return vector_db_instance\n",
    "\n",
    "def query_invoice_data(vector_db: LanceDb, question: str):\n",
    "    \"\"\"\n",
    "    Query the invoice data using the vector database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the question\n",
    "        query_embedding = phi_ollama_embedder.get_embedding(question)\n",
    "        \n",
    "        # Perform the search (correct LanceDB syntax)\n",
    "        results = vector_db.search(query_embedding).limit(3).to_list()\n",
    "        \n",
    "        # Combine the context from top results\n",
    "        context = \"\\n\".join([result[\"content\"] for result in results])\n",
    "        \n",
    "        # Setup LLM chain\n",
    "        llm = LCOllama(model=model_id)\n",
    "        chain = rag_prompt_template | llm | StrOutputParser()\n",
    "        \n",
    "        # Get answer\n",
    "        response = chain.invoke({\n",
    "            \"context\": context,\n",
    "            \"query\": question\n",
    "        })\n",
    "        \n",
    "        display(Markdown(f\"**Question:** {question}\"))\n",
    "        display(Markdown(f\"**Answer:** {response}\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying data: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the vector db instance\n",
    "    vector_db = main()\n",
    "    \n",
    "    # Only run queries if we have a valid vector db\n",
    "    if vector_db:\n",
    "        print(\"\\nInvoice Query System Ready!\")\n",
    "        query_invoice_data(vector_db, \"What is the total amount due for this invoice?\")\n",
    "        query_invoice_data(vector_db, \"Who is the customer and what is their address?\")\n",
    "        query_invoice_data(vector_db, \"What is the Invoice Number and Date?\")\n",
    "        query_invoice_data(vector_db, \"What are the payment terms?\")\n",
    "        query_invoice_data(vector_db, \"Who is the salesperson mentioned on the invoice?\",)\n",
    "        query_invoice_data(vector_db, \"What is the description of the item purchased and its quantity?\")\n",
    "        query_invoice_data(vector_db,\"What is the unit price of the decorative clay pottery?\")\n",
    "        query_invoice_data(vector_db, \"What is the subtotal before taxes and shipping?\")\n",
    "        query_invoice_data(vector_db,\"How much is the sales tax and shipping & handling?\")\n",
    "        query_invoice_data(vector_db, \"Are there any special instructions or comments about the shipment?\")\n",
    "        query_invoice_data(vector_db,  \"What is the phone number of Pottery & Co.?\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Failed to initialize vector database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb6b35-7bcc-4d77-99e3-3c94558efc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
