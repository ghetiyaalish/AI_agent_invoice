{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73311631-5212-4ad0-be3c-f663364e35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --default-timeout=100 install -q ollama langchain langchain-community langchain-core pypdf reportlab lancedb beautifulsoup4 unstructured phidata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c63ac8f-e481-4107-aba7-abd36620dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Ollama model 'gemma:2b' initialized for LLM and Embedder.\n",
      "PDF extraction function defined.\n",
      "Invoice data processing function defined.\n",
      "RAG prompt template defined.\n",
      "Using existing invoice.pdf at: C:\\Users\\ALISH\\Agent Practice\\tmp\\invoice.pdf\n",
      "Processing PDF: C:\\Users\\ALISH\\Agent Practice\\tmp\\invoice.pdf\n",
      "Split PDF into 1 chunks.\n",
      "Using embedding dimension: 2048\n",
      "Created new table with proper schema\n",
      "Successfully inserted 1 chunks\n",
      "\n",
      "Invoice Query System Ready!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the total amount due for this invoice?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"total_amount_due\": \"$1234.56\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Who is the customer and what is their address?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"customer_name\": \"ABC Corp\",\n",
       "  \"customer_address\": null\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the Invoice Number and Date?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"Invoice Number\": \"INV-2023-001\",\n",
       "  \"Invoice Date\": \"October 26, 2023\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What are the payment terms?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"payment_terms\": \"Net 30\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Who is the salesperson mentioned on the invoice?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"name\": \"Salesperson Name\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the description of the item purchased and its quantity?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"product_description\": \"Product X\",\n",
       "  \"product_quantity\": 2\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the unit price of the decorative clay pottery?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"unit_price\": null\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the subtotal before taxes and shipping?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"Subtotal\": \"$1234.56\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** How much is the sales tax and shipping & handling?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"sales_tax\": null,\n",
       "  \"shipping_handling\": null\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Are there any special instructions or comments about the shipment?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"line_item_1\": {\n",
       "    \"product_name\": \"Product X\",\n",
       "    \"quantity\": 2,\n",
       "    \"price\": 300.00\n",
       "  },\n",
       "  \"line_item_2\": {\n",
       "    \"product_name\": \"Service Y\",\n",
       "    \"quantity\": 1,\n",
       "    \"price\": 634.56\n",
       "  }\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the phone number of Pottery & Co.?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** {\n",
       "  \"phone_number\": null\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup (UPDATED)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_ollama import OllamaLLM as LCOllama \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document as LangChainDocument\n",
    "import uuid  \n",
    "import pyarrow as pa \n",
    "from phi.model.ollama import Ollama as PhiOllama\n",
    "from phi.vectordb.lancedb import LanceDb, SearchType\n",
    "from phi.embedder.ollama import OllamaEmbedder as PhiOllamaEmbedder\n",
    "from phi.document import Document as PhiDocument\n",
    "import PyPDF2\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas as r_canvas\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n",
    "model_id = \"gemma:2b\"\n",
    "# Initialize Ollama model for phi-agent\n",
    "phi_ollama_model = PhiOllama(id=model_id)\n",
    "# Initialize Ollama embedder for phi-agent's vector DB\n",
    "phi_ollama_embedder = PhiOllamaEmbedder(model=model_id)\n",
    "\n",
    "print(f\"Ollama model '{model_id}' initialized for LLM and Embedder.\")\n",
    "\n",
    "\n",
    "# Cell 3: PDF Text Extraction Function (No Changes)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from a given PDF file using PyPDF2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"PDF extraction function defined.\")\n",
    "\n",
    "\n",
    "def process_invoice_data(pdf_path: str) -> list[PhiDocument]:\n",
    "    \"\"\"\n",
    "    Extracts text from PDF and returns properly formatted PhiDocuments\n",
    "    \"\"\"\n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        print(\"No text extracted from PDF.\")\n",
    "        return []\n",
    "\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    \n",
    "    # Split text and create PhiDocuments\n",
    "    text_chunks = text_splitter.split_text(text)\n",
    "    phi_chunks = [\n",
    "        PhiDocument(\n",
    "            name=f\"chunk_{i}\",\n",
    "            content=chunk,  # Using 'content' consistently\n",
    "            meta={\"source\": pdf_path}\n",
    "        )\n",
    "        for i, chunk in enumerate(text_chunks)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Split PDF into {len(phi_chunks)} chunks.\")\n",
    "    return phi_chunks\n",
    "print(\"Invoice data processing function defined.\")\n",
    "\n",
    "\n",
    "# Cell 5: Setup Vector Database (LanceDB) (No Changes)\n",
    "\n",
    "def setup_vector_db(chunks: list[PhiDocument]) -> LanceDb:\n",
    "    \"\"\"\n",
    "    More robust database setup with proper cleanup\n",
    "    \"\"\"\n",
    "    import lancedb\n",
    "    \n",
    "    db_uri = \"tmp/lancedb_invoices\"\n",
    "    \n",
    "    # Clean up any existing database\n",
    "    if os.path.exists(db_uri):\n",
    "        try:\n",
    "            import shutil\n",
    "            shutil.rmtree(db_uri)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not clean database directory: {e}\")\n",
    "    \n",
    "    os.makedirs(db_uri, exist_ok=True)\n",
    "    \n",
    "    # Connect to LanceDB with retry logic\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            db = lancedb.connect(db_uri)\n",
    "            \n",
    "            # Get embedding dimension\n",
    "            test_embedding = phi_ollama_embedder.get_embedding(\"test\")\n",
    "            dim = len(test_embedding)\n",
    "            print(f\"Using embedding dimension: {dim}\")\n",
    "            \n",
    "            # Define schema\n",
    "            schema = pa.schema([\n",
    "                pa.field(\"id\", pa.string()),\n",
    "                pa.field(\"content\", pa.string()),\n",
    "                pa.field(\"vector\", pa.list_(pa.float32(), dim)),\n",
    "                pa.field(\"metadata\", pa.string())\n",
    "            ])\n",
    "            \n",
    "            # Create table\n",
    "            table = db.create_table(\"invoice_data\", schema=schema)\n",
    "            print(\"Created new table with proper schema\")\n",
    "            \n",
    "            # Insert documents with batch processing\n",
    "            if chunks:\n",
    "                data = []\n",
    "                for chunk in chunks:\n",
    "                    try:\n",
    "                        embedding = phi_ollama_embedder.get_embedding(chunk.content)\n",
    "                        data.append({\n",
    "                            \"id\": str(uuid.uuid4()),\n",
    "                            \"content\": chunk.content,\n",
    "                            \"vector\": embedding,\n",
    "                            \"metadata\": json.dumps(chunk.meta if hasattr(chunk, 'meta') else {})\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing chunk: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if data:\n",
    "                    # Insert in batches to prevent timeouts\n",
    "                    batch_size = 5\n",
    "                    for i in range(0, len(data), batch_size):\n",
    "                        batch = data[i:i + batch_size]\n",
    "                        table.add(batch)\n",
    "                    print(f\"Successfully inserted {len(data)} chunks\")\n",
    "                else:\n",
    "                    print(\"No valid chunks to insert\")\n",
    "            \n",
    "            return table\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying... Error: {e}\")\n",
    "            time.sleep(1)  # Add delay between retries\n",
    "# Cell 6: Define RAG Prompt (No Changes)\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are an expert AI assistant specialized in extracting precise details from invoice documents. \"\n",
    "        \"Your goal is to accurately answer questions based *only* on the provided invoice context. \"\n",
    "        \"If the information is not present in the context, state that you cannot find it. \"\n",
    "        \"For all extractions, return the response in a clear JSON format with appropriate keys for the extracted data.\"\n",
    "        \"\\n---CONTEXT---\\n\"\n",
    "        \"{context}\"\n",
    "    )),\n",
    "    (\"human\", \"Query: {query}\")\n",
    "])\n",
    "\n",
    "print(\"RAG prompt template defined.\")\n",
    "\n",
    "# Cell 7: Main Execution Flow (UPDATED)\n",
    "# Cell 7: Main Execution Flow (Updated)\n",
    "def main():\n",
    "    # Setup: Create 'tmp' folder and define invoice PDF path\n",
    "    pdf_dir = os.path.join(os.getcwd(), \"tmp\")\n",
    "    os.makedirs(pdf_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(pdf_dir, \"invoice.pdf\")\n",
    "\n",
    "    # Create a dummy invoice if it doesn't exist\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(\"Invoice not exist\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Using existing invoice.pdf at: {pdf_path}\")\n",
    "\n",
    "    # Process PDF and setup the vector database\n",
    "    chunks = process_invoice_data(pdf_path)\n",
    "    if not chunks:\n",
    "        print(\"Exiting: No text found in PDF.\")\n",
    "        return None\n",
    "    \n",
    "    vector_db_instance = setup_vector_db(chunks)\n",
    "    return vector_db_instance\n",
    "\n",
    "def query_invoice_data(vector_db: LanceDb, question: str):\n",
    "    \"\"\"\n",
    "    Query the invoice data using the vector database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the question\n",
    "        query_embedding = phi_ollama_embedder.get_embedding(question)\n",
    "        \n",
    "        # Perform the search (correct LanceDB syntax)\n",
    "        results = vector_db.search(query_embedding).limit(3).to_list()\n",
    "        \n",
    "        # Combine the context from top results\n",
    "        context = \"\\n\".join([result[\"content\"] for result in results])\n",
    "        \n",
    "        # Setup LLM chain\n",
    "        llm = LCOllama(model=model_id)\n",
    "        chain = rag_prompt_template | llm | StrOutputParser()\n",
    "        \n",
    "        response = chain.invoke({\n",
    "            \"context\": context,\n",
    "            \"query\": question\n",
    "        })\n",
    "        \n",
    "        display(Markdown(f\"**Question:** {question}\"))\n",
    "        display(Markdown(f\"**Answer:** {response}\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying data: {e}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    vector_db = main()\n",
    "    \n",
    "    if vector_db:\n",
    "        print(\"\\nInvoice Query System Ready!\")\n",
    "        query_invoice_data(vector_db, \"What is the total amount due for this invoice?\")\n",
    "        query_invoice_data(vector_db, \"Who is the customer and what is their address?\")\n",
    "        query_invoice_data(vector_db, \"What is the Invoice Number and Date?\")\n",
    "        query_invoice_data(vector_db, \"What are the payment terms?\")\n",
    "        query_invoice_data(vector_db, \"Who is the salesperson mentioned on the invoice?\",)\n",
    "        query_invoice_data(vector_db, \"What is the description of the item purchased and its quantity?\")\n",
    "        query_invoice_data(vector_db,\"What is the unit price of the decorative clay pottery?\")\n",
    "        query_invoice_data(vector_db, \"What is the subtotal before taxes and shipping?\")\n",
    "        query_invoice_data(vector_db,\"How much is the sales tax and shipping & handling?\")\n",
    "        query_invoice_data(vector_db, \"Are there any special instructions or comments about the shipment?\")\n",
    "        query_invoice_data(vector_db,  \"What is the phone number of Pottery & Co.?\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Failed to initialize vector database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb6b35-7bcc-4d77-99e3-3c94558efc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
