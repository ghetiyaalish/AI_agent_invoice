{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673b0c09-9d10-4a9e-a926-b2689c70d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Ollama model 'gemma:2b' initialized for LLM and Embedder.\n",
      "PDF extraction function defined.\n",
      "Invoice data processing function defined.\n",
      "RAG prompt template defined (modified for plain text output).\n",
      "Using existing invoice.pdf at: C:\\Users\\ALISH\\Agent Practice\\invoice.pdf\n",
      "Processing PDF: C:\\Users\\ALISH\\Agent Practice\\invoice.pdf\n",
      "Split PDF into 2 chunks.\n",
      "Cleaned existing database directory: C:\\Users\\ALISH\\Agent Practice\\lancedb_invoices\n",
      "Using embedding dimension: 2048\n",
      "Created new table with proper schema\n",
      "Successfully inserted 2 chunks into C:\\Users\\ALISH\\Agent Practice\\lancedb_invoices\n",
      "\n",
      "Invoice Query System Ready!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the total amount due for this invoice?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** The total amount due for this invoice is $1389.99."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Who is the customer and what is their address?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** The customer's name and address are not explicitly mentioned in the context, so I cannot answer this question from the provided context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the Invoice Number and Date?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** Invoice Number: #100\n",
       "Date: 1/1/23"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What are the payment terms?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** The payment terms are not explicitly mentioned in the context, so I cannot answer this question from the provided context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Who is the salesperson mentioned on the invoice?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** The context does not provide the salesperson's name, so I cannot answer this question from the provided context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the description of the item purchased and its quantity?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** The item purchased is not explicitly mentioned in the context, so I cannot answer this question from the provided context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the unit price of the decorative clay pottery?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** The unit price of the decorative clay pottery is not explicitly stated in the context, so I cannot answer this question from the provided context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the subtotal before taxes and shipping?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** The subtotal before taxes and shipping is $1300.00."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** How much is the sales tax and shipping & handling?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:** Sales tax: 65.00\n",
       "Shipping & handling: 24.99"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error querying data: lance error: LanceError(IO): Execution error: Not found: C:/Users/ALISH/Agent Practice/lancedb_invoices/invoice_data.lance/data/ac0a73ce-2e7d-4262-adcd-cec363a839a9.lance, C:\\Users\\runneradmin\\.cargo\\registry\\src\\index.crates.io-1949cf8c6b5b557f\\lance-io-0.31.1\\src\\local.rs:122:31, C:\\Users\\runneradmin\\.cargo\\registry\\src\\index.crates.io-1949cf8c6b5b557f\\lance-0.31.1\\src\\dataset\\scanner.rs:2955:83\n",
      "Error querying data: lance error: LanceError(IO): Execution error: Not found: C:/Users/ALISH/Agent Practice/lancedb_invoices/invoice_data.lance/data/ac0a73ce-2e7d-4262-adcd-cec363a839a9.lance, C:\\Users\\runneradmin\\.cargo\\registry\\src\\index.crates.io-1949cf8c6b5b557f\\lance-io-0.31.1\\src\\local.rs:122:31, C:\\Users\\runneradmin\\.cargo\\registry\\src\\index.crates.io-1949cf8c6b5b557f\\lance-0.31.1\\src\\dataset\\scanner.rs:2955:83\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "import time\n",
    "\n",
    "from langchain_ollama import OllamaLLM as LCOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document as LangChainDocument\n",
    "import uuid\n",
    "import pyarrow as pa\n",
    "from phi.model.ollama import Ollama as PhiOllama\n",
    "from phi.vectordb.lancedb import LanceDb, SearchType\n",
    "from phi.embedder.ollama import OllamaEmbedder as PhiOllamaEmbedder\n",
    "from phi.document import Document as PhiDocument\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas as r_canvas\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n",
    "model_id = \"gemma:2b\"\n",
    "phi_ollama_embedder = PhiOllamaEmbedder(model=model_id)\n",
    "\n",
    "print(f\"Ollama model '{model_id}' initialized for LLM and Embedder.\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from a given PDF file using PyPDF2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"PDF extraction function defined.\")\n",
    "\n",
    "def process_invoice_data(pdf_path: str) -> list[PhiDocument]:\n",
    "    \"\"\"\n",
    "    Extracts text from PDF and returns properly formatted PhiDocuments\n",
    "    \"\"\"\n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        print(\"No text extracted from PDF.\")\n",
    "        return []\n",
    "\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    \n",
    "    text_chunks = text_splitter.split_text(text)\n",
    "    phi_chunks = [\n",
    "        PhiDocument(\n",
    "            name=f\"chunk_{i}\",\n",
    "            content=chunk,\n",
    "            meta={\"source\": pdf_path}\n",
    "        )\n",
    "        for i, chunk in enumerate(text_chunks)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Split PDF into {len(phi_chunks)} chunks.\")\n",
    "    return phi_chunks\n",
    "print(\"Invoice data processing function defined.\")\n",
    "\n",
    "\n",
    "# Cell 5: Setup Vector Database (LanceDB) (MODIFIED AGAIN)\n",
    "\n",
    "def setup_vector_db(chunks: list[PhiDocument], db_path: str) -> LanceDb: # Added db_path parameter\n",
    "    \"\"\"\n",
    "    More robust database setup with proper cleanup\n",
    "    \"\"\"\n",
    "    import lancedb\n",
    "    \n",
    "    db_uri = db_path # Use the passed db_path directly\n",
    "    \n",
    "    if os.path.exists(db_uri):\n",
    "        try:\n",
    "            import shutil\n",
    "            shutil.rmtree(db_uri)\n",
    "            print(f\"Cleaned existing database directory: {db_uri}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not clean database directory {db_uri}: {e}\")\n",
    "    \n",
    "    os.makedirs(db_uri, exist_ok=True)\n",
    "    \n",
    "    # Connect to LanceDB with retry logic\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            db = lancedb.connect(db_uri)\n",
    "            \n",
    "            # Get embedding dimension\n",
    "            test_embedding = phi_ollama_embedder.get_embedding(\"test\")\n",
    "            dim = len(test_embedding)\n",
    "            print(f\"Using embedding dimension: {dim}\")\n",
    "            \n",
    "            # Define schema\n",
    "            schema = pa.schema([\n",
    "                pa.field(\"id\", pa.string()),\n",
    "                pa.field(\"content\", pa.string()),\n",
    "                pa.field(\"vector\", pa.list_(pa.float32(), dim)),\n",
    "                pa.field(\"metadata\", pa.string())\n",
    "            ])\n",
    "            \n",
    "            # Create table\n",
    "            table = db.create_table(\"invoice_data\", schema=schema)\n",
    "            print(\"Created new table with proper schema\")\n",
    "            \n",
    "            # Insert documents with batch processing\n",
    "            if chunks:\n",
    "                data = []\n",
    "                for chunk in chunks:\n",
    "                    try:\n",
    "                        embedding = phi_ollama_embedder.get_embedding(chunk.content)\n",
    "                        data.append({\n",
    "                            \"id\": str(uuid.uuid4()),\n",
    "                            \"content\": chunk.content,\n",
    "                            \"vector\": embedding,\n",
    "                            \"metadata\": json.dumps(chunk.meta if hasattr(chunk, 'meta') else {})\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing chunk: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if data:\n",
    "                    # Insert in batches to prevent timeouts\n",
    "                    batch_size = 5\n",
    "                    for i in range(0, len(data), batch_size):\n",
    "                        batch = data[i:i + batch_size]\n",
    "                        table.add(batch)\n",
    "                    print(f\"Successfully inserted {len(data)} chunks into {db_uri}\")\n",
    "                else:\n",
    "                    print(\"No valid chunks to insert\")\n",
    "            \n",
    "            return table\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying... Error: {e}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "# Cell 6: Define RAG Prompt (MODIFIED for plain text output - NO CHANGE FROM LAST TIME)\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are an expert AI assistant specialized in extracting precise details from invoice documents. \"\n",
    "        \"Your goal is to accurately answer questions based *only* on the provided invoice context. \"\n",
    "        \"If the information is not present in the context, state that you cannot find it. \"\n",
    "        \"Provide your answer directly as plain text, concisely and clearly, without any JSON formatting.\"\n",
    "        \"\\n---CONTEXT---\\n\"\n",
    "        \"{context}\"\n",
    "    )),\n",
    "    (\"human\", \"Query: {query}\")\n",
    "])\n",
    "\n",
    "print(\"RAG prompt template defined (modified for plain text output).\")\n",
    "\n",
    "# Cell 7: Main Execution Logic (MODIFIED AGAIN)\n",
    "\n",
    "def main():\n",
    "    # Define the base directory for your project.\n",
    "    # Based on image_87f6e5.png, 'Agent Practice' is the root where your script and invoice.pdf reside.\n",
    "    project_root_dir = os.getcwd() \n",
    "    \n",
    "    # Define the full path to the invoice PDF\n",
    "    pdf_path = os.path.join(project_root_dir, \"invoice.pdf\")\n",
    "\n",
    "    # Define the path for the LanceDB database\n",
    "    lancedb_dir = os.path.join(project_root_dir, \"lancedb_invoices\")\n",
    "\n",
    "    # Check if the invoice.pdf exists at the specified location\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(\"File not found\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Using existing invoice.pdf at: {pdf_path}\")\n",
    "        \n",
    "    # Process PDF and setup the vector database\n",
    "    chunks = process_invoice_data(pdf_path)\n",
    "    if not chunks:\n",
    "        print(\"Exiting: No text found in PDF.\")\n",
    "        return None\n",
    "        \n",
    "    vector_db_instance = setup_vector_db(chunks, db_path=lancedb_dir) # Pass the explicit LanceDB path\n",
    "    return vector_db_instance\n",
    "\n",
    "def query_invoice_data(vector_db: LanceDb, question: str):\n",
    "    \"\"\"\n",
    "    Query the invoice data using the vector database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the question\n",
    "        query_embedding = phi_ollama_embedder.get_embedding(question)\n",
    "\n",
    "        # Perform the search \n",
    "        results = vector_db.search(query_embedding).limit(5).to_list()\n",
    "        \n",
    "        # Combine the context from top results\n",
    "        context = \"\\n\".join([result[\"content\"] for result in results])\n",
    "        \n",
    "        # Setup LLM chain\n",
    "        llm = LCOllama(model=model_id)\n",
    "        chain = rag_prompt_template | llm | StrOutputParser()\n",
    "        \n",
    "        # Get answer\n",
    "        response = chain.invoke({\n",
    "            \"context\": context,\n",
    "            \"query\": question\n",
    "        })\n",
    "        \n",
    "        display(Markdown(f\"**Question:** {question}\"))\n",
    "        display(Markdown(f\"**Answer:** {response}\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying data: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the vector db instance\n",
    "    vector_db = main()\n",
    "    \n",
    "    # Only run queries if we have a valid vector db\n",
    "    if vector_db:\n",
    "        print(\"\\nInvoice Query System Ready!\")\n",
    "        query_invoice_data(vector_db, \"What is the total amount due for this invoice?\")\n",
    "        query_invoice_data(vector_db, \"Who is the customer and what is their address?\")\n",
    "        query_invoice_data(vector_db, \"What is the Invoice Number and Date?\")\n",
    "        query_invoice_data(vector_db, \"What are the payment terms?\")\n",
    "        query_invoice_data(vector_db, \"Who is the salesperson mentioned on the invoice?\")\n",
    "        query_invoice_data(vector_db, \"What is the description of the item purchased and its quantity?\")\n",
    "        query_invoice_data(vector_db,\"What is the unit price of the decorative clay pottery?\")\n",
    "        query_invoice_data(vector_db, \"What is the subtotal before taxes and shipping?\")\n",
    "        query_invoice_data(vector_db,\"How much is the sales tax and shipping & handling?\")\n",
    "        query_invoice_data(vector_db, \"Are there any special instructions or comments about the shipment?\")\n",
    "        query_invoice_data(vector_db, \"What is the phone number of Pottery & Co.?\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Failed to initialize vector database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3f996-977f-4938-82ef-5ad58d1520f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41721f8b-5473-4267-a963-182d61b4e957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576feee-00e3-492e-a60d-183f85acbfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d22e28-9851-4919-99f5-b7d68011a071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
