{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8d6f40-aa39-4b46-ae28-409003d1243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: phidata in c:\\users\\alish\\anaconda3\\lib\\site-packages (2.7.10)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.177.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-generativeai) (6.31.1)\n",
      "Requirement already satisfied: pydantic in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-generativeai) (4.14.1)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.37 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.3.72)\n",
      "Requirement already satisfied: docstring-parser in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (0.16)\n",
      "Requirement already satisfied: gitpython in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (3.1.37)\n",
      "Requirement already satisfied: httpx in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (0.27.2)\n",
      "Requirement already satisfied: pydantic-settings in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (2.10.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (6.0.1)\n",
      "Requirement already satisfied: rich in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (13.3.5)\n",
      "Requirement already satisfied: tomli in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (2.2.1)\n",
      "Requirement already satisfied: typer in c:\\users\\alish\\anaconda3\\lib\\site-packages (from phidata) (0.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from gitpython->phidata) (4.0.7)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\alish\\anaconda3\\lib\\site-packages (from httpx->phidata) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\alish\\anaconda3\\lib\\site-packages (from httpx->phidata) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alish\\anaconda3\\lib\\site-packages (from httpx->phidata) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\alish\\anaconda3\\lib\\site-packages (from httpx->phidata) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\alish\\anaconda3\\lib\\site-packages (from httpx->phidata) (1.3.0)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->phidata) (0.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from rich->phidata) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from rich->phidata) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alish\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from typer->phidata) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from typer->phidata) (1.5.4)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->phidata) (4.0.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->phidata) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alish\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "   ---------------------------------------- 0.0/155.4 kB ? eta -:--:--\n",
      "   ---------- ---------------------------- 41.0/155.4 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  153.6/155.4 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 155.4/155.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.3 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.4/1.3 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.9/1.3 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.0/42.0 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 160.8/160.8 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 434.8/434.8 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.177.0-py3-none-any.whl (13.7 MB)\n",
      "   ---------------------------------------- 0.0/13.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/13.7 MB 26.2 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 1.0/13.7 MB 12.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/13.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.1/13.7 MB 13.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.3/13.7 MB 13.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.1/13.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.5/13.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.0/13.7 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.5/13.7 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.0/13.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.6/13.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.9/13.7 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.4/13.7 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.9/13.7 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.3/13.7 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.8/13.7 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.2/13.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.7/13.7 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.2/13.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.7/13.7 MB 10.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.2/13.7 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.7/13.7 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.1/13.7 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.6/13.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.9/13.7 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.3/13.7 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.5/13.7 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.5/13.7 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.1/13.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.6/13.7 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.7/13.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.7/13.7 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB ? eta 0:00:00\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, proto-plus, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.31.1\n",
      "    Uninstalling protobuf-6.31.1:\n",
      "      Successfully uninstalled protobuf-6.31.1\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.177.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 grpcio-status-1.71.2 httplib2-0.22.0 langchain-google-genai-2.0.10 proto-plus-1.26.1 protobuf-5.29.5 uritemplate-4.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai langchain-google-genai phidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6db887-8a20-4c18-985f-34010fc4cb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Initialized Gemini 2.5 Pro with 1M token context window\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Extract all line items as JSON with fields: description, quantity, unit_price, total"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Analysis:**\n",
       "```json\n",
       "[\n",
       "  {\n",
       "    \"description\": \"Decorative clay pottery (LG)\",\n",
       "    \"quantity\": 100,\n",
       "    \"unit_price\": 13.00,\n",
       "    \"total\": 1300.00\n",
       "  }\n",
       "]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Analyze payment terms across all invoices and identify the most common pattern"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Analysis:**\n",
       "Due on receipt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Compare invoice dates versus payment due dates and calculate average days early/late"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Analysis:**\n",
       "| Invoice Date | Payment Due Date | Days to Pay (Early/Late) |\n",
       "| :--- | :--- | :--- |\n",
       "| 1/1/23 | Due on receipt | 0 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Generate a markdown table of all customers and their total amounts due"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Analysis:**\n",
       "| Customer | Total Amount Due |\n",
       "| :--- | :--- |\n",
       "| Mollie Grau | 1389.99 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Verify tax calculations for all line items and flag discrepancies"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Analysis:**\n",
       "| Description | Extracted Subtotal | Extracted Tax | Calculated Tax (5.00% Rate) | Discrepancy |\n",
       "| :--- | :--- | :--- | :--- | :--- |\n",
       "| Invoice Total | $1,300.00 | $65.00 | $65.00 | $0.00 |\n",
       "\n",
       "**Conclusion:** The sales tax of $65.00 is correctly calculated at a 5.00% rate on the subtotal of $1,300.00. There are no discrepancies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup (Premium Optimized)\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "import time\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import uuid\n",
    "import pyarrow as pa\n",
    "from phi.vectordb.lancedb import LanceDb\n",
    "from phi.document import Document as PhiDocument\n",
    "import PyPDF2\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n",
    "# Initialize with premium configuration\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyB5LHC0ntTSiM4rG8FNd3mQV6XqXDwx_lE\"  # Your premium key\n",
    "\n",
    "# Premium model selection\n",
    "gemini_model = \"models/gemini-2.5-pro\"  # Using 1M token context\n",
    "embedder = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Enhanced LLM configuration for premium\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=gemini_model,\n",
    "    temperature=0,\n",
    "    max_retries=5,\n",
    "    request_timeout=120,\n",
    "    convert_system_message_to_human=False,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "print(f\"Initialized Gemini 2.5 Pro with 1M token context window\")\n",
    "\n",
    "# PDF processing with larger chunk size for premium\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Enhanced PDF extraction handling multi-column layouts\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"PDF extraction error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_invoice_data(pdf_path: str) -> list[PhiDocument]:\n",
    "    \"\"\"Optimized for premium model's larger context\"\"\"\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    # Larger chunks for premium models\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=5000,  # Increased from 1000\n",
    "        chunk_overlap=500,\n",
    "        length_function=len\n",
    "    )\n",
    "    \n",
    "    return [\n",
    "        PhiDocument(\n",
    "            name=f\"chunk_{i}\",\n",
    "            content=chunk,\n",
    "            meta_data={\n",
    "                \"source\": pdf_path,\n",
    "                \"page\": i//3  # Approximate page tracking\n",
    "            }\n",
    "        )\n",
    "        for i, chunk in enumerate(splitter.split_text(text))\n",
    "    ]\n",
    "\n",
    "# Vector DB with premium optimizations\n",
    "def setup_vector_db(chunks: list[PhiDocument], db_path: str) -> LanceDb:\n",
    "    \"\"\"Enhanced for premium model features\"\"\"\n",
    "    import lancedb\n",
    "    \n",
    "    if os.path.exists(db_path):\n",
    "        import shutil\n",
    "        shutil.rmtree(db_path)\n",
    "    \n",
    "    os.makedirs(db_path, exist_ok=True)\n",
    "    \n",
    "    db = lancedb.connect(db_path)\n",
    "    test_embedding = embedder.embed_query(\"test\")\n",
    "    dim = len(test_embedding)\n",
    "    \n",
    "    schema = pa.schema([\n",
    "        pa.field(\"id\", pa.string()),\n",
    "        pa.field(\"content\", pa.string()),\n",
    "        pa.field(\"vector\", pa.list_(pa.float32(), dim)),\n",
    "        pa.field(\"metadata\", pa.string()),\n",
    "        pa.field(\"page_ref\", pa.int32())  # Added for premium context tracking\n",
    "    ])\n",
    "    \n",
    "    table = db.create_table(\"invoice_data\", schema=schema)\n",
    "    \n",
    "    if chunks:\n",
    "        # Batch processing with error handling\n",
    "        batch_size = 50\n",
    "        for i in range(0, len(chunks), batch_size):\n",
    "            batch = chunks[i:i + batch_size]\n",
    "            try:\n",
    "                embeddings = embedder.embed_documents([ch.content for ch in batch])\n",
    "                data = [{\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"content\": ch.content,\n",
    "                    \"vector\": emb,\n",
    "                    \"metadata\": json.dumps(ch.meta_data),\n",
    "                    \"page_ref\": ch.meta_data.get(\"page\", 0)\n",
    "                } for ch, emb in zip(batch, embeddings)]\n",
    "                table.add(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Batch {i//batch_size} failed: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "    return table\n",
    "\n",
    "# Premium-optimized RAG prompt\n",
    "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"INVOICE ANALYTICS ENGINE (Gemini 2.5 Pro)\\n\"\n",
    "        \"Leverage your 1M token context to:\\n\"\n",
    "        \"1. Extract exact values from complex layouts\\n\"\n",
    "        \"2. Cross-reference across document sections\\n\"\n",
    "        \"3. Validate numerical consistency\\n\"\n",
    "        \"4. Structure output for direct database insertion\\n\\n\"\n",
    "        \"CONTEXT:\\n{context}\"\n",
    "    )),\n",
    "    (\"human\", (\n",
    "        \"Query: {query}\\n\"\n",
    "        \"Respond with:\\n\"\n",
    "        \"- Direct extracted values\\n\"\n",
    "        \"- JSON if requesting multiple fields\\n\"\n",
    "        \"- Markdown tables for comparative analysis\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Main execution with premium features\n",
    "def main():\n",
    "    pdf_path = os.path.join(os.getcwd(), \"invoice.pdf\")\n",
    "    lancedb_dir = os.path.join(os.getcwd(), \"lancedb_invoices_premium\")\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(\"Error: invoice.pdf not found!\")\n",
    "        return None\n",
    "    \n",
    "    chunks = process_invoice_data(pdf_path)\n",
    "    return setup_vector_db(chunks, lancedb_dir) if chunks else None\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def query_invoice_data(vector_db: LanceDb, question: str):\n",
    "    \"\"\"Premium-enhanced query with analytics\"\"\"\n",
    "    try:\n",
    "        query_embedding = embedder.embed_query(question)\n",
    "        results = vector_db.search(query_embedding).limit(8).to_list()  # More context\n",
    "        \n",
    "        context = \"\\nDOCUMENT SECTIONS:\\n\" + \"\\n---\\n\".join(\n",
    "            f\"PAGE {r['page_ref']}:\\n{r['content']}\" \n",
    "            for r in results\n",
    "        )\n",
    "        \n",
    "        response = (rag_prompt_template | llm | StrOutputParser()).invoke({\n",
    "            \"context\": context, \n",
    "            \"query\": question\n",
    "        })\n",
    "        \n",
    "        display(Markdown(f\"**Question:** {question}\"))\n",
    "        display(Markdown(f\"**Analysis:**\\n{response}\"))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Query failed: {type(e).__name__}: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vector_db = main()\n",
    "    if vector_db:\n",
    "        premium_questions = [\n",
    "            \"Extract all line items as JSON with fields: description, quantity, unit_price, total\",\n",
    "            \"Analyze payment terms across all invoices and identify the most common pattern\",\n",
    "            \"Compare invoice dates versus payment due dates and calculate average days early/late\",\n",
    "            \"Generate a markdown table of all customers and their total amounts due\",\n",
    "            \"Verify tax calculations for all line items and flag discrepancies\"\n",
    "        ]\n",
    "        for q in premium_questions:\n",
    "            query_invoice_data(vector_db, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c87d42-270a-4ebf-8229-49c91d48676a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
